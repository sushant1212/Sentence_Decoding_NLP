{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "import torchtext\n",
    "import bcolz\n",
    "import unicodedata\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = s.replace(\"'\",\"\")\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    nrows = len(df)\n",
    "    real_preprocess = []\n",
    "    df['Content_Parsed_1'] = df['transcription']\n",
    "    for row in range(0, nrows):\n",
    "\n",
    "        # Create an empty list containing preprocessed words\n",
    "        real_preprocess = []\n",
    "\n",
    "        # Save the text and its words into an object\n",
    "        text = df.loc[row]['transcription']\n",
    "        text = normalizeString(text)\n",
    "\n",
    "\n",
    "        df.loc[row]['Content_Parsed_1'] = text\n",
    "\n",
    "    df['action'] = df['action'].str.lower()\n",
    "    df['object'] = df['object'].str.lower()\n",
    "    df['location'] = df['location'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(df):\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    # Lemmatizing the content\n",
    "    nrows = len(df)\n",
    "    lemmatized_text_list = []\n",
    "    for row in range(0, nrows):\n",
    "\n",
    "        # Create an empty list containing lemmatized words\n",
    "        lemmatized_list = []\n",
    "\n",
    "        # Save the text and its words into an object\n",
    "        text = df.loc[row]['Content_Parsed_1']\n",
    "        text_words = text.split(\" \")\n",
    "\n",
    "        # Iterate through every word to lemmatize\n",
    "        for word in text_words:\n",
    "            lemmatized_list.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "\n",
    "        # Join the list\n",
    "        lemmatized_text = \" \".join(lemmatized_list)\n",
    "\n",
    "        # Append to the list containing the texts\n",
    "        lemmatized_text_list.append(lemmatized_text)\n",
    "    df['Content_Parsed_2'] = lemmatized_text_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df = \"E:/saarthi/task_data/train_data.csv\"\n",
    "with open(path_df, 'rb') as data:\n",
    "    df = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df_val = \"E:/saarthi/task_data/valid_data.csv\"\n",
    "with open(path_df, 'rb') as data:\n",
    "    df_val = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(df_val)\n",
    "lemmatize(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(df)\n",
    "lemmatize(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Glove Word embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = \"E:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = bcolz.open(f'{glove_path}/6B.50.dat')[:]\n",
    "words = pickle.load(open(f'{glove_path}/6B.50_words.pkl', 'rb'))\n",
    "word2idx = pickle.load(open(f'{glove_path}/6B.50_idx.pkl', 'rb'))\n",
    "glove = {w: vectors[word2idx[w]] for w in words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vocab = []\n",
    "nrows = len(df)\n",
    "for row in range(0, nrows):\n",
    "    text = df.loc[row]['Content_Parsed_2']\n",
    "    text_words = text.split(\" \")\n",
    "    for word in text_words:\n",
    "        if word not in target_vocab:\n",
    "            target_vocab.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vocab = []\n",
    "nrows = len(df_val)\n",
    "for row in range(0, nrows):\n",
    "    text = df.loc[row]['Content_Parsed_2']\n",
    "    text_words = text.split(\" \")\n",
    "    for word in text_words:\n",
    "        if word not in target_vocab:\n",
    "            target_vocab.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = len(df)\n",
    "for row in range(0, nrows):\n",
    "    text = df.loc[row]['action']\n",
    "    text_words = text.split(\" \")\n",
    "    for word in text_words:\n",
    "        if word not in target_vocab:\n",
    "            target_vocab.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = len(df_val)\n",
    "for row in range(0, nrows):\n",
    "    text = df.loc[row]['action']\n",
    "    text_words = text.split(\" \")\n",
    "    for word in text_words:\n",
    "        if word not in target_vocab:\n",
    "            target_vocab.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = len(df)\n",
    "for row in range(0, nrows):\n",
    "    text = df.loc[row]['object']\n",
    "    text_words = text.split(\" \")\n",
    "    for word in text_words:\n",
    "        if word not in target_vocab:\n",
    "            target_vocab.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = len(df_val)\n",
    "for row in range(0, nrows):\n",
    "    text = df.loc[row]['object']\n",
    "    text_words = text.split(\" \")\n",
    "    for word in text_words:\n",
    "        if word not in target_vocab:\n",
    "            target_vocab.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = len(df)\n",
    "for row in range(0, nrows):\n",
    "    text = df.loc[row]['location']\n",
    "    text_words = text.split(\" \")\n",
    "    for word in text_words:\n",
    "        if word not in target_vocab:\n",
    "            target_vocab.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = len(df_val)\n",
    "for row in range(0, nrows):\n",
    "    text = df.loc[row]['location']\n",
    "    text_words = text.split(\" \")\n",
    "    for word in text_words:\n",
    "        if word not in target_vocab:\n",
    "            target_vocab.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating an embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(target_vocab)\n",
    "input_size = 50\n",
    "\n",
    "embedding_matrix = torch.zeros((vocab_size, input_size))\n",
    "for w in target_vocab:\n",
    "    i = word_to_idx(w)\n",
    "    \n",
    "    embedding_matrix[i, :] = torch.from_numpy(glove[w]).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_idx(word):\n",
    "    for i, w in enumerate(target_vocab):\n",
    "        if w == word:\n",
    "            return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_matrix(sentence):\n",
    "    words = sentence.split(\" \")\n",
    "    n = len(words)\n",
    "    m = torch.zeros((n, input_size))\n",
    "    for i, w in enumerate(words):\n",
    "        m[i] = embedding_matrix[word_to_idx(w)]\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_index(sentence):\n",
    "    w = sentence.split(\" \")\n",
    "    l = []\n",
    "    for word in w:\n",
    "        l.append(word_to_idx(word))\n",
    "    t = torch.tensor(l, dtype=torch.float32)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = len(target_vocab)\n",
    "input_size = 50\n",
    "hidden_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = x.unsqueeze(0)\n",
    "        output, hidden = self.gru(x, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "5\n",
      "torch.Size([1, 1, 50])\n",
      "torch.Size([1, 1, 50])\n"
     ]
    }
   ],
   "source": [
    "s = \"turn down the bathroom temperature\"\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "matrix = sentence_to_matrix(s)\n",
    "print(matrix[0].unsqueeze(0).shape)\n",
    "encoder = EncoderRNN(input_size, hidden_size)\n",
    "hidden = encoder.initHidden()\n",
    "for i in range(matrix.shape[0]):\n",
    "    out, hidden = encoder(matrix[i].unsqueeze(0), hidden)\n",
    "print(out.shape)\n",
    "print(hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        output = F.relu(x)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output_softmax = self.softmax(self.out(output[0]))\n",
    "        return output, hidden, output_softmax\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decrease heat washroom\n",
      "tensor([25])\n",
      "tensor([25])\n",
      "tensor([22])\n"
     ]
    }
   ],
   "source": [
    "decoder_hidden = hidden\n",
    "decoder_input = torch.ones((1,1,50))\n",
    "decoder = DecoderRNN(hidden_size, output_size)\n",
    "output_sentence = df.loc[3][\"action\"] + \" \"+ df.loc[3][\"object\"] + \" \" + df.loc[3][\"location\"]\n",
    "print(output_sentence)\n",
    "target_tensor = sentence_to_index(output_sentence)\n",
    "criterion = nn.NLLLoss()\n",
    "loss = 0\n",
    "for i in range(target_tensor.shape[0]):\n",
    "    decoder_input, decoder_hidden, decoder_output_softmax = decoder(decoder_input, decoder_hidden)\n",
    "    loss += criterion(decoder_output_softmax, target_tensor[i].unsqueeze(0).long())\n",
    "    print(torch.argmax(decoder_output_softmax, dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "    \n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei].unsqueeze(0), encoder_hidden)\n",
    "\n",
    "    decoder_input = torch.ones((1,1,50))\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "   \n",
    "    for i in range(target_tensor.shape[0]):\n",
    "        decoder_input, decoder_hidden, decoder_output_softmax = decoder(decoder_input, decoder_hidden)\n",
    "        loss += criterion(decoder_output_softmax, target_tensor[i].unsqueeze(0).long())\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01, df):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    nrows = len(df)\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        i = random.randint(0, n_iters)\n",
    "        i = (i % nrows)\n",
    "        \n",
    "        s = df.loc[i][\"Content_Parsed_2\"]\n",
    "\n",
    "        \n",
    "        input_tensor = sentence_to_matrix(s)\n",
    "        \n",
    "        output_sentence = df.loc[i][\"action\"] + \" \"+ df.loc[i][\"object\"] + \" \" + df.loc[i][\"location\"]\n",
    "        target_tensor = sentence_to_index(output_sentence)\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(encoder, decoder, input_sentence):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    input_tensor = sentence_to_matrix(input_sentence)\n",
    "    decoder_input = torch.ones((1,1,50))\n",
    "    input_length = input_tensor.size(0)\n",
    "    \n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei].unsqueeze(0), encoder_hidden)\n",
    "    \n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    for i in range(3):\n",
    "        decoder_input, decoder_hidden, decoder_output_softmax = decoder(decoder_input, decoder_hidden)\n",
    "        idx = torch.argmax(decoder_output_softmax)\n",
    "        print(target_vocab[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, input_sentence, target_tensor):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    input_tensor = sentence_to_matrix(input_sentence)\n",
    "    decoder_input = torch.ones((1,1,50))\n",
    "    input_length = input_tensor.size(0)\n",
    "    \n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei].unsqueeze(0), encoder_hidden)\n",
    "    \n",
    "    decoder_hidden = encoder_hidden\n",
    "    correct = 0\n",
    "    for i in range(3):\n",
    "        decoder_input, decoder_hidden, decoder_output_softmax = decoder(decoder_input, decoder_hidden)\n",
    "        idx = torch.argmax(decoder_output_softmax)\n",
    "        if(idx == target_tensor[i]):\n",
    "            correct += 1\n",
    "    if(correct == 3):\n",
    "        return 1\n",
    "    else: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 3s (- 9m 23s) (1000 0%) 2.1604\n",
      "0m 7s (- 9m 40s) (2000 1%) 1.0210\n",
      "0m 11s (- 9m 27s) (3000 2%) 0.5684\n",
      "0m 16s (- 9m 47s) (4000 2%) 0.4079\n",
      "0m 20s (- 9m 48s) (5000 3%) 0.3162\n",
      "0m 24s (- 9m 44s) (6000 4%) 0.2225\n",
      "0m 28s (- 9m 43s) (7000 4%) 0.1346\n",
      "0m 32s (- 9m 35s) (8000 5%) 0.0895\n",
      "0m 36s (- 9m 36s) (9000 6%) 0.0623\n",
      "0m 40s (- 9m 33s) (10000 6%) 0.0533\n",
      "0m 45s (- 9m 36s) (11000 7%) 0.0448\n",
      "0m 49s (- 9m 31s) (12000 8%) 0.0309\n",
      "0m 53s (- 9m 23s) (13000 8%) 0.0360\n",
      "0m 58s (- 9m 24s) (14000 9%) 0.0314\n",
      "1m 2s (- 9m 21s) (15000 10%) 0.0271\n",
      "1m 6s (- 9m 15s) (16000 10%) 0.0204\n",
      "1m 10s (- 9m 13s) (17000 11%) 0.0163\n",
      "1m 14s (- 9m 8s) (18000 12%) 0.0150\n",
      "1m 19s (- 9m 7s) (19000 12%) 0.0162\n",
      "1m 24s (- 9m 8s) (20000 13%) 0.0127\n",
      "1m 29s (- 9m 10s) (21000 14%) 0.0138\n",
      "1m 35s (- 9m 14s) (22000 14%) 0.0132\n",
      "1m 40s (- 9m 14s) (23000 15%) 0.0171\n",
      "1m 46s (- 9m 18s) (24000 16%) 0.0113\n",
      "1m 52s (- 9m 23s) (25000 16%) 0.0107\n",
      "1m 57s (- 9m 18s) (26000 17%) 0.0094\n",
      "2m 2s (- 9m 17s) (27000 18%) 0.0114\n",
      "2m 7s (- 9m 16s) (28000 18%) 0.0154\n",
      "2m 13s (- 9m 15s) (29000 19%) 0.0077\n",
      "2m 19s (- 9m 17s) (30000 20%) 0.0088\n",
      "2m 24s (- 9m 15s) (31000 20%) 0.0059\n",
      "2m 30s (- 9m 13s) (32000 21%) 0.0065\n",
      "2m 36s (- 9m 13s) (33000 22%) 0.0060\n",
      "2m 42s (- 9m 12s) (34000 22%) 0.0066\n",
      "2m 46s (- 9m 8s) (35000 23%) 0.0066\n",
      "2m 52s (- 9m 4s) (36000 24%) 0.0098\n",
      "2m 57s (- 9m 3s) (37000 24%) 0.0059\n",
      "3m 2s (- 8m 59s) (38000 25%) 0.0065\n",
      "3m 8s (- 8m 56s) (39000 26%) 0.0062\n",
      "3m 13s (- 8m 51s) (40000 26%) 0.0057\n",
      "3m 18s (- 8m 46s) (41000 27%) 0.0103\n",
      "3m 24s (- 8m 45s) (42000 28%) 0.0099\n",
      "3m 30s (- 8m 42s) (43000 28%) 0.0056\n",
      "3m 35s (- 8m 38s) (44000 29%) 0.0044\n",
      "3m 41s (- 8m 35s) (45000 30%) 0.0038\n",
      "3m 46s (- 8m 31s) (46000 30%) 0.0058\n",
      "3m 51s (- 8m 26s) (47000 31%) 0.0040\n",
      "3m 56s (- 8m 22s) (48000 32%) 0.0065\n",
      "4m 1s (- 8m 17s) (49000 32%) 0.0050\n",
      "4m 6s (- 8m 13s) (50000 33%) 0.0034\n",
      "4m 12s (- 8m 10s) (51000 34%) 0.0035\n",
      "4m 17s (- 8m 4s) (52000 34%) 0.0024\n",
      "4m 22s (- 8m 0s) (53000 35%) 0.0028\n",
      "4m 28s (- 7m 57s) (54000 36%) 0.0025\n",
      "4m 34s (- 7m 53s) (55000 36%) 0.0028\n",
      "4m 38s (- 7m 48s) (56000 37%) 0.0022\n",
      "4m 44s (- 7m 43s) (57000 38%) 0.0024\n",
      "4m 49s (- 7m 39s) (58000 38%) 0.0020\n",
      "4m 54s (- 7m 33s) (59000 39%) 0.0022\n",
      "5m 0s (- 7m 30s) (60000 40%) 0.0019\n",
      "5m 5s (- 7m 26s) (61000 40%) 0.0019\n",
      "5m 10s (- 7m 21s) (62000 41%) 0.0020\n",
      "5m 16s (- 7m 17s) (63000 42%) 0.0020\n",
      "5m 21s (- 7m 12s) (64000 42%) 0.0017\n",
      "5m 26s (- 7m 7s) (65000 43%) 0.0018\n",
      "5m 31s (- 7m 2s) (66000 44%) 0.0018\n",
      "5m 37s (- 6m 58s) (67000 44%) 0.0016\n",
      "5m 43s (- 6m 53s) (68000 45%) 0.0017\n",
      "5m 48s (- 6m 49s) (69000 46%) 0.0017\n",
      "5m 53s (- 6m 44s) (70000 46%) 0.0017\n",
      "5m 59s (- 6m 39s) (71000 47%) 0.0017\n",
      "6m 4s (- 6m 34s) (72000 48%) 0.0017\n",
      "6m 10s (- 6m 30s) (73000 48%) 0.0016\n",
      "6m 15s (- 6m 25s) (74000 49%) 0.0015\n",
      "6m 21s (- 6m 21s) (75000 50%) 0.0015\n",
      "6m 27s (- 6m 16s) (76000 50%) 0.0015\n",
      "6m 32s (- 6m 12s) (77000 51%) 0.0013\n",
      "6m 38s (- 6m 7s) (78000 52%) 0.0014\n",
      "6m 43s (- 6m 2s) (79000 52%) 0.0013\n",
      "6m 49s (- 5m 57s) (80000 53%) 0.0013\n",
      "6m 54s (- 5m 52s) (81000 54%) 0.0013\n",
      "7m 0s (- 5m 48s) (82000 54%) 0.0013\n",
      "7m 5s (- 5m 43s) (83000 55%) 0.0012\n",
      "7m 11s (- 5m 38s) (84000 56%) 0.0012\n",
      "7m 16s (- 5m 33s) (85000 56%) 0.0013\n",
      "7m 21s (- 5m 28s) (86000 57%) 0.0012\n",
      "7m 26s (- 5m 23s) (87000 57%) 0.0011\n",
      "7m 31s (- 5m 17s) (88000 58%) 0.0012\n",
      "7m 36s (- 5m 13s) (89000 59%) 0.0011\n",
      "7m 42s (- 5m 8s) (90000 60%) 0.0012\n",
      "7m 49s (- 5m 4s) (91000 60%) 0.0012\n",
      "7m 55s (- 4m 59s) (92000 61%) 0.0011\n",
      "8m 1s (- 4m 55s) (93000 62%) 0.0010\n",
      "8m 8s (- 4m 50s) (94000 62%) 0.0011\n",
      "8m 13s (- 4m 45s) (95000 63%) 0.0010\n",
      "8m 18s (- 4m 40s) (96000 64%) 0.0011\n",
      "8m 24s (- 4m 35s) (97000 64%) 0.0010\n",
      "8m 29s (- 4m 30s) (98000 65%) 0.0011\n",
      "8m 34s (- 4m 24s) (99000 66%) 0.0010\n",
      "8m 39s (- 4m 19s) (100000 66%) 0.0009\n",
      "8m 45s (- 4m 14s) (101000 67%) 0.0010\n",
      "8m 50s (- 4m 9s) (102000 68%) 0.0010\n",
      "8m 55s (- 4m 4s) (103000 68%) 0.0009\n",
      "9m 1s (- 3m 59s) (104000 69%) 0.0009\n",
      "9m 7s (- 3m 54s) (105000 70%) 0.0010\n",
      "9m 13s (- 3m 49s) (106000 70%) 0.0009\n",
      "9m 19s (- 3m 44s) (107000 71%) 0.0009\n",
      "9m 25s (- 3m 39s) (108000 72%) 0.0009\n",
      "9m 31s (- 3m 34s) (109000 72%) 0.0008\n",
      "9m 37s (- 3m 30s) (110000 73%) 0.0009\n",
      "9m 43s (- 3m 25s) (111000 74%) 0.0009\n",
      "9m 50s (- 3m 20s) (112000 74%) 0.0008\n",
      "9m 55s (- 3m 15s) (113000 75%) 0.0008\n",
      "10m 2s (- 3m 10s) (114000 76%) 0.0008\n",
      "10m 7s (- 3m 5s) (115000 76%) 0.0008\n",
      "10m 13s (- 2m 59s) (116000 77%) 0.0008\n",
      "10m 19s (- 2m 54s) (117000 78%) 0.0008\n",
      "10m 25s (- 2m 49s) (118000 78%) 0.0008\n",
      "10m 31s (- 2m 44s) (119000 79%) 0.0008\n",
      "10m 37s (- 2m 39s) (120000 80%) 0.0008\n",
      "10m 43s (- 2m 34s) (121000 80%) 0.0008\n",
      "10m 49s (- 2m 28s) (122000 81%) 0.0008\n",
      "10m 54s (- 2m 23s) (123000 82%) 0.0008\n",
      "10m 59s (- 2m 18s) (124000 82%) 0.0008\n",
      "11m 4s (- 2m 12s) (125000 83%) 0.0007\n",
      "11m 9s (- 2m 7s) (126000 84%) 0.0007\n",
      "11m 14s (- 2m 2s) (127000 84%) 0.0007\n",
      "11m 20s (- 1m 56s) (128000 85%) 0.0007\n",
      "11m 27s (- 1m 51s) (129000 86%) 0.0007\n",
      "11m 32s (- 1m 46s) (130000 86%) 0.0007\n",
      "11m 38s (- 1m 41s) (131000 87%) 0.0008\n",
      "11m 44s (- 1m 36s) (132000 88%) 0.0007\n",
      "11m 49s (- 1m 30s) (133000 88%) 0.0007\n",
      "11m 55s (- 1m 25s) (134000 89%) 0.0007\n",
      "12m 1s (- 1m 20s) (135000 90%) 0.0007\n",
      "12m 7s (- 1m 14s) (136000 90%) 0.0007\n",
      "12m 13s (- 1m 9s) (137000 91%) 0.0007\n",
      "12m 18s (- 1m 4s) (138000 92%) 0.0007\n",
      "12m 23s (- 0m 58s) (139000 92%) 0.0007\n",
      "12m 29s (- 0m 53s) (140000 93%) 0.0007\n",
      "12m 35s (- 0m 48s) (141000 94%) 0.0006\n",
      "12m 41s (- 0m 42s) (142000 94%) 0.0006\n",
      "12m 46s (- 0m 37s) (143000 95%) 0.0006\n",
      "12m 52s (- 0m 32s) (144000 96%) 0.0006\n",
      "12m 58s (- 0m 26s) (145000 96%) 0.0006\n",
      "13m 4s (- 0m 21s) (146000 97%) 0.0006\n",
      "13m 10s (- 0m 16s) (147000 98%) 0.0006\n",
      "13m 16s (- 0m 10s) (148000 98%) 0.0006\n",
      "13m 22s (- 0m 5s) (149000 99%) 0.0006\n",
      "13m 27s (- 0m 0s) (150000 100%) 0.0006\n"
     ]
    }
   ],
   "source": [
    "encoder = EncoderRNN(input_size, hidden_size).to(device)\n",
    "decoder = DecoderRNN(hidden_size, output_size)\n",
    "\n",
    "trainIters(encoder, decoder, 150000, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11566\n",
      "11566\n",
      "Accuracy on Val test : 100.0\n"
     ]
    }
   ],
   "source": [
    "n = len(df_val)\n",
    "total = 0\n",
    "correct = 0\n",
    "for i in range(n):\n",
    "    output_sentence = df_val.loc[i][\"action\"] + \" \"+ df_val.loc[i][\"object\"] + \" \" + df_val.loc[i][\"location\"]\n",
    "    target_tensor = sentence_to_index(output_sentence)\n",
    "    \n",
    "    input_sentence = df_val.loc[i][\"Content_Parsed_2\"]\n",
    "    correct += evaluate(encoder, decoder, input_sentence, target_tensor)\n",
    "    total += 1\n",
    "print(correct)\n",
    "print(total)\n",
    "print(f\"Accuracy on Val test : {(float(correct)/total)*100}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
